{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b31e4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 150)\n",
    "sns.set_style('darkgrid')\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
    "matplotlib.rcParams['figure.facecolor'] = '#00000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ae55fafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\weather-dataset-rattle-package\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package\"\n",
    "od.download(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f34f81b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weatherAUS.csv']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"weather-dataset-rattle-package\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "225c8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"weather-dataset-rattle-package/weatherAUS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "abf230ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 145460 entries, 0 to 145459\n",
      "Data columns (total 23 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   Date           145460 non-null  object \n",
      " 1   Location       145460 non-null  object \n",
      " 2   MinTemp        143975 non-null  float64\n",
      " 3   MaxTemp        144199 non-null  float64\n",
      " 4   Rainfall       142199 non-null  float64\n",
      " 5   Evaporation    82670 non-null   float64\n",
      " 6   Sunshine       75625 non-null   float64\n",
      " 7   WindGustDir    135134 non-null  object \n",
      " 8   WindGustSpeed  135197 non-null  float64\n",
      " 9   WindDir9am     134894 non-null  object \n",
      " 10  WindDir3pm     141232 non-null  object \n",
      " 11  WindSpeed9am   143693 non-null  float64\n",
      " 12  WindSpeed3pm   142398 non-null  float64\n",
      " 13  Humidity9am    142806 non-null  float64\n",
      " 14  Humidity3pm    140953 non-null  float64\n",
      " 15  Pressure9am    130395 non-null  float64\n",
      " 16  Pressure3pm    130432 non-null  float64\n",
      " 17  Cloud9am       89572 non-null   float64\n",
      " 18  Cloud3pm       86102 non-null   float64\n",
      " 19  Temp9am        143693 non-null  float64\n",
      " 20  Temp3pm        141851 non-null  float64\n",
      " 21  RainToday      142199 non-null  object \n",
      " 22  RainTomorrow   142193 non-null  object \n",
      "dtypes: float64(16), object(7)\n",
      "memory usage: 25.5+ MB\n"
     ]
    }
   ],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7f2db7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.dropna(subset=[\"RainTomorrow\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b87bf821",
   "metadata": {},
   "outputs": [],
   "source": [
    "year  = pd.to_datetime(raw_df.Date).dt.year\n",
    "\n",
    "train_df = raw_df[year<2015]\n",
    "val_df = raw_df[year==2015]\n",
    "test_df = raw_df[year>2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ceed690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = list(raw_df.columns)[1:-1]\n",
    "target_col = \"RainTomorrow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "93ebf1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = train_df[input_cols].copy()\n",
    "train_targets = train_df[target_col].copy()\n",
    "val_inputs = val_df[input_cols].copy()\n",
    "val_targets = val_df[target_col].copy()\n",
    "test_inputs = test_df[input_cols].copy()\n",
    "test_targets = test_df[target_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "43d0a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = train_inputs.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = train_inputs.select_dtypes('object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ff58e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"mean\").fit(raw_df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a7b5cc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[numeric_cols] = imputer.transform(train_inputs[numeric_cols])\n",
    "val_inputs[numeric_cols] = imputer.transform(val_inputs[numeric_cols])\n",
    "test_inputs[numeric_cols] = imputer.transform(test_inputs[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a75efa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "de0d4853",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(raw_df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "177c7187",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs[numeric_cols] = scaler.transform(train_inputs[numeric_cols])\n",
    "val_inputs[numeric_cols] = scaler.transform(val_inputs[numeric_cols])\n",
    "test_inputs[numeric_cols] = scaler.transform(test_inputs[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "70542b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindSpeed9am</th>\n",
       "      <th>WindSpeed3pm</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.007075</td>\n",
       "      <td>0.030246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125620</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021097</td>\n",
       "      <td>0.026871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.952830</td>\n",
       "      <td>0.948960</td>\n",
       "      <td>0.666307</td>\n",
       "      <td>0.485517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669231</td>\n",
       "      <td>0.850575</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971901</td>\n",
       "      <td>0.9632</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.943038</td>\n",
       "      <td>0.925144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
       "min  0.007075  0.030246  0.000000     0.000000       0.0       0.007752   \n",
       "max  0.952830  0.948960  0.666307     0.485517       1.0       1.000000   \n",
       "\n",
       "     WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  \\\n",
       "min      0.000000      0.000000         0.04          0.0     0.125620   \n",
       "max      0.669231      0.850575         1.00          1.0     0.971901   \n",
       "\n",
       "     Pressure3pm  Cloud9am  Cloud3pm   Temp9am   Temp3pm  \n",
       "min       0.0816  0.000000  0.000000  0.021097  0.026871  \n",
       "max       0.9632  0.888889  0.888889  0.943038  0.925144  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_inputs.describe().loc[[\"min\",\"max\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d42339f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0c788c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore').fit(raw_df[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c8faaa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_cols = list(encoder.get_feature_names_out(categorical_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "036e875f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n",
      "C:\\Users\\Adithya Narayan\\AppData\\Local\\Temp\\ipykernel_21348\\1584174743.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])\n"
     ]
    }
   ],
   "source": [
    "train_inputs[encoded_cols] = encoder.transform(train_inputs[categorical_cols])\n",
    "val_inputs[encoded_cols] = encoder.transform(val_inputs[categorical_cols])\n",
    "test_inputs[encoded_cols] = encoder.transform(test_inputs[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e945596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_inputs[numeric_cols + encoded_cols]\n",
    "X_val = val_inputs[numeric_cols + encoded_cols]\n",
    "X_test = test_inputs[numeric_cols + encoded_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb94066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
